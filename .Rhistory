serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
install.packages("widgetframe")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
vignette('programming')
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
install.packages('bookdown')
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::new_post_addin()
library(htmltools)
div(HTML("I like <u>turtles</u>"))
HTML('<meta http-equiv="refresh" content="0; URL='http://new-website.com'" />')
HTML('<meta http-equiv="refresh" content="0; URL=\'http://new-website.com\'" />')
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown::serve_site()
library(stringr)
Letters
LETTERS
letters
## 특정 단어 찾기
stringr::words
stringr::fruit
stringr::sentences
## 특정 단어 찾기
stringr::words
test_sentence <- '아버지가방에들어가신다'
str_locate(test_sentence, '가방')
str_locate(test_sentence, '가방들어')
str_locate(test_sentence, '가방에에')
str_locate(test_sentence, '가방에')
str_locate_all(test_sentence, '가방')
list(test_sentence, test_sentence, test_sentence)
str_locate_all(list(test_sentence, test_sentence, test_sentence), '가방')
str_locate(list(test_sentence, test_sentence, test_sentence), '가방에') # 문장에서 패턴에 해당하는 문자가 등장하는 지점부터 끝나는 지점까지의 위치를 반환
str_locate(list(test_sentence, test_sentence, test_sentence), '가방에') %>% class()
str_locate_all(list(test_sentence, test_sentence, test_sentence), '가방') %>% class()
str_locate(words, 'stay')
str_locate(head(words), 'area')
str_locate(head(words,100), 'area')
library(dplyr)
str_locate(head(words,100), 'area') %>% as_tibble()
stringr::words
str_locate(head(words), 'a') %>% as_tibble()
str_extract(head(words), 'a')
str_extract_all(head(words), 'a') # 패턴에 해당하는 글자가 존재하면 그 글자를 반환
str_extract_all(head(words), 'a', simplify = T) # ~all 함수는 출력값이 list형
str_match(head(words), 'a')
head(words)
str_extract(head(words), 'ab') # 패턴에 해당하는 글자가 존재하면 그 글자를 반환
str_extract_all(head(words), 'ab') # ~all 함수는 출력값이 list형
str_extract_all(head(words), 'ab', simplify = T) # ~all 함수는 출력값이 list형
str_extract_all(head(words), 'ab', simplify = T) # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_extract_all(head(words), 'ab') # ~all 함수는 출력값이 list형
str_match(head(words), 'a')
str_match(head(words), 'ab')
head(words)
str_match(head(words), 'abo')
str_extract(head(words), 'abo')
str_locate(head(words), 'abo')
str_match(head(words), 'abo')
str_match_all(head(words), 'abo')
str_match_all(head(words), 'abo', simplyfy = T) # str_extract_all() 함수와 동일 기능
str_match_all(head(words), 'abo') # str_extract_all() 함수와 동일 기능
str_extract_all(head(words), 'ab', simplify = T) # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_extract_all(head(words), 'ab') # ~all 함수는 출력값이 list형
str_match_all(head(words), 'abo', simplyfy = T) # str_extract_all() 함수와 동일 기능
str_extract_all(head(words), 'ab') # ~all 함수는 출력값이 list형
str_match_all(head(words), 'abo') # str_extract_all() 함수와 동일 기능
str_extract(head(words), 'abo') # 패턴에 해당하는 글자가 존재하면 그 글자를 반환
str_extract_all(head(words), 'abo') # ~all 함수는 출력값이 list형
str_match_all(head(words), 'abo') # str_extract_all() 함수와 동일 기능
str_extract_all(head(words), 'abo', simplify = T) # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_extract(head(words), 'abo') # 패턴에 해당하는 글자가 존재하면 그 글자를 반환
str_match(head(words), 'abo') # str_extract() 함수와 동일 기능
str_extract_all(head(words), 'abo', simplify = T) # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_match_all(head(words), 'abo') # str_extract_all() 함수와 동일 기능
str_match_all(head(words), 'abo') %>% class() # str_extract_all() 함수와 동일 기능
str_extract_all(head(words), 'abo', simplify = T) # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_match_all(head(words), 'abo') %>% unlist() # str_extract_all() 함수와 동일 기능
str_extract(head(words), 'abo') %>% class() # 패턴에 해당하는 글자가 존재하면 그 글자를 반환, 반환결과는 vector표기
str_extract_all(head(words), 'abo') # ~all 함수는 출력값이 list형
str_extract_all(head(words), 'abo') %>% class()
str_extract_all(head(words), 'abo', simplify = T) %>% class() # 'slimplyfy = T' 옵션은 반환을 matrix로 해준다.
str_match(head(words), 'abo') # str_extract() 함수와 동일 기능 , 반환결과는 matrix
str_match_all(head(words), 'abo') # str_extract_all() 함수와 동일 기능
str_locate(test_sentence, '가방에') # 문장에서 패턴에 해당하는 문자가 등장하는 지점부터 끝나는 지점까지의 위치를 반환
str_locate_all(list(test_sentence, test_sentence, test_sentence), '가방') # ~all 함수는 list형식으로 반환
str_locate(head(words), 'a') %>% as_tibble() # 의미와는 상관없이 해당하는 글자가 존재하면 무조건 표기함
## 특정 단어 변환
str_replace(head(words), pattern = 'abo', replacement = 'z')
## 특정 단어 변환
str_replace(string = head(words), pattern = 'abo', replacement = 'z')
## 특정 단어 변환
str_replace(string = head(words),
pattern = 'abo',
replacement = 'z') %>% class()
str_replace_all(string = head(words),
pattern = 'abo',
replacement = 'z') # "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
str_replace_all(string = head(words),
pattern = 'abo',
replacement = 'z') %>% class()# "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
## 특정 단어 변환
str_replace(string = head(words),
pattern = c('a','b'),
replacement = 'z') # "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
## 특정 단어 변환
str_replace(string = head(words),
pattern = c('a','b','o'),
replacement = 'z') # "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
str_replace_all(string = head(words),
pattern = c('a','b','o'),
replacement = 'z')# "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
str_replace_all(string = head(words),
pattern = c('a,b,o'),
replacement = 'z')# "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
str_replace_all(string = head(words),
pattern = c('a|b|o'),
replacement = 'z')# "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
## 특정 단어 변환
str_replace(string = head(words),
pattern = c('a|b|o'),
replacement = 'z') # "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
## 특정 단어 변환
str_replace(string = head(words),
pattern = c('a|b|o'),
replacement = 'z') # "string"에서 "pattern"에 해당하는 값을 "replacement" 값으로 바꿔준다. 출력값은 character vector
str_replace_all(string = head(words),
pattern = c('a|b|o'),
replacement = 'z')# str_replace() 함수는 패턴에 해당하는 첫번째 값만 변환하는 반면, str_replace_all()함수는 패턴에 해당하는 모든 값을 변환해준다
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(1)
blogdown::serve_site()
blogdown::serve_site
blogdown::serve_site()
serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
see <- function(rx, match) str_view_all("abc ABC 123\t.!?\\(){}\n", rx)
see('a*')
library(rvest)
library(dplyr)
library(stringr)
library(knitr)
see('Ab+')
library(blogdown)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
```{r}
blogdown::serve_site()
blogdown::serve_site()
data.frame(
"\\\\ + 정규문자" = c('\\\\n',
'\\\\t'),
"의미"            = c('줄바꿈',
'탭'),
"example"         = c('see("\\\\n")',
'see("\\\\t")'),
"result"          = c(as.character(as.tags(see('\\\\n'))),
as.character(as.tags(see('\\\\t')))),
check.names = F
) %>% kable(escape = F, align = 'c', format = 'html',  table.attr = "style='width:30%;'") %>%
kable_styling(latex_options = c("scale_up"), full_width = F) %>%
column_spec(1, width = '20em') %>%
column_spec(2, width = '20em')
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
rsthemes::install_rsthemes(include_base16 = TRUE)
rsthemes::install_rsthemes()
rsthemes::remove_rsthemes()
rsthemes::install_rsthemes(include_base16 = TRUE)
rsthemes::try_rsthemes()
rsthemes::use_theme_favorite()
rsthemes::set_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
N
if (interactive() && requireNamespace("rsthemes", quietly = TRUE)) {
rsthemes::set_theme_favorite(c(
"base16 Hopscotch {rsthemes}", "base16 Ocean {rsthemes}",
"base16 Tomorrow Night {rsthemes}"
))
}
use_theme_favorite()
rethemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::set_theme_favorite()
rsthemes::set_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::list_rsthemes()
rsthemes::try_rsthemes()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
if (interactive() && requireNamespace("rsthemes", quietly = TRUE)) {
rsthemes::set_theme_favorite(c(
"base16 Brewer {rsthemes}", "base16 Hopscotch {rsthemes}",
"base16 Spacemacs {rsthemes}", "Nord Polar Night Aurora {rsthemes}",
"Oceanic Plus {rsthemes}", "One Dark {rsthemes}",
"base16 Hopscotch {rsthemes}", "base16 Ocean {rsthemes}",
"base16 Tomorrow Night {rsthemes}"
))
}
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
+   rsthemes::set_theme_favorite(c(
+     "base16 Brewer {rsthemes}", "base16 Hopscotch {rsthemes}",
+     "base16 Spacemacs {rsthemes}", "Nord Polar Night Aurora {rsthemes}",
+     "Oceanic Plus {rsthemes}", "One Dark {rsthemes}",
+     "base16 Hopscotch {rsthemes}", "base16 Ocean {rsthemes}",
+     "base16 Tomorrow Night {rsthemes}"
+   ))
rsthemes::set_theme_favorite(c(
+     "base16 Brewer {rsthemes}", "base16 Hopscotch {rsthemes}",
+     "base16 Spacemacs {rsthemes}", "Nord Polar Night Aurora {rsthemes}",
+     "Oceanic Plus {rsthemes}", "One Dark {rsthemes}",
+     "base16 Hopscotch {rsthemes}", "base16 Ocean {rsthemes}",
+     "base16 Tomorrow Night {rsthemes}"
+   ))
+ }
rsthemes::set_theme_favorite(c(
"base16 Brewer {rsthemes}", "base16 Hopscotch {rsthemes}",
"base16 Spacemacs {rsthemes}", "Nord Polar Night Aurora {rsthemes}",
"Oceanic Plus {rsthemes}", "One Dark {rsthemes}",
"base16 Hopscotch {rsthemes}", "base16 Ocean {rsthemes}",
"base16 Tomorrow Night {rsthemes}"
))
usethis::edit_r_profile()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::use_theme_favorite()
rsthemes::list_rsthemes()
usethis::edit_r_profile()
use_theme_favorite()
library(rsthemes)
library(rsthemes)
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
use_theme_favorite()
usethis::edit_r_profile()
usethis::edit_r_profile()
usethis::edit_r_profile()
blogdown::serve_site()
blogdown::serve_site()
library(installr)
check.for.updates.R()
install.R()
library(blogdown)
blogdown::serve_site()
devtools::install_github('haven-jeon/KoSpacing')
install.packages('hashmap')
devtools::install_github("nathan-russell/hashmap")
devtools::install_github('haven-jeon/KoSpacing')
library(KoSpacing)
set_env()
library(KoSpacing)
spacing("김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.")
spacing('test_sentence')
spacing(test_sentence)
"김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다."
"김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다." %>% tm::removePunctuation()
library(dplyr)
"김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다." %>% tm::removePunctuation()
tm::removePunctuation("김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.")
tm::removeSparseTerms("김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.")
tm::tm_map("김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.", FUN = stripWhitespace)
library(rjaba )
library(rJava )
library(rJava)
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jre1.8.0_261') # rJava Path 오류시
library(rJava)
library(NLP4kec)
NLP4kec::r_parser_r(test_sentence)
NLP4kec::r_parser_r(test_sentence, language = 'ko')
test_sentence2 <- "김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다."
NLP4kec::r_parser_r(test_sentence2, language = 'ko')
"김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다."
NLP4kec::r_parser_r(test_sentence2, language = 'ko')
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::tm_map()
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::VectorSource() %>%
tm::VCorpus() %>%
tm::tm_map()
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::VectorSource() %>%
tm::VCorpus() %>%
tm::tm_map(., FUN = stripWhitespace)
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::VectorSource() %>%
tm::VCorpus() %>%
tm::tm_map(., FUN = stripWhitespace)
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::VectorSource() %>%
tm::VCorpus() %>%
tm::tm_map(., FUN = 'stripWhitespace')
NLP4kec::r_parser_r(test_sentence2, language = 'ko') %>%
tm::VectorSource() %>%
tm::VCorpus()
library(stringr)
str_remove_all(test_sentence2, '[[:space:]]')
str_remove_all(test_sentence2, '[:space:]')
str_remove(test_sentence2, '[:space:]')
str_split(test_sentence2, '[:space:]')
spacing("김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.")
spacing("김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.") %>% str_split('[:space:]')
install.packages(c("dplyr", "htmltools", "kableExtra", "knitr", "stringr"))
blogdown::serve_site()
install.packages('blogdown')
blogdown::serve_site()
blogdown::serve_site()
## 매칭
<br>
<br>
## 매칭
<br>
<br>
<br>
## 카운팅
<br>
<br>
<br>
## 포함
<br>
<br>
<br>
## 위치
<br>
<br>
blogdown::serve_site()
dplyr::glimpse(regex_sentence); head(regex_sentence); tail(regex_sentence)
blogdown::serve_site()
blogdown::serve_site()
str_subset(regex_sentences, '^(The)')  # 시작이 'The'인 문장을 반환
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
install.packages("giphyr")
giphyr:::gif_Addin()
giphyr:::gif_Addin()
library(giphyr)
library(giphyr)
giphyr:::gif_Addin()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown::serve_site()
library(blogdown)
q()
demo()
contributors()
blogdown::serve_site()
blogdown::install_hugo()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
print('hi')
blogdown::serve_site()
blogdown::serve_site()
knitr::include_graphics('C:/Users/JDW/Desktop/GIT/academic-kickstart/public/project/2020-09-27-producex101_files/final.jpg')
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown::serve_site()
---
title: 텍스트 분석을 통한 프로듀스X101 데뷔조 예측
author: JDW
date: '2019-12-07'
slug: redirect-test
categories: []
tags: []
summary: ''
authors: []
external_link: 'https://montewood.github.io/ProduceX101'
image:
caption: 'project/2020-09-27-producex101_files/final.jpg'
focal_point: ''
preview_only: no
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''
slides: ''
---
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown:::new_post_addin()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown::serve_site()
